{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f3f9b-5221-4f1e-bfd6-de3715875444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages.\n",
    "!pip install -q --upgrade kfp==1.8.14\n",
    "!pip install -q kubeflow-katib==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66392f87-ea99-4ab2-8353-025af565b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from os import environ\n",
    "\n",
    "from kubeflow.katib import ApiClient\n",
    "from kubeflow.katib import V1beta1ExperimentSpec\n",
    "from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "from kubeflow.katib import V1beta1ParameterSpec\n",
    "from kubeflow.katib import V1beta1FeasibleSpace\n",
    "from kubeflow.katib import V1beta1TrialTemplate\n",
    "from kubeflow.katib import V1beta1TrialParameterSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95c849-833a-4b94-84f3-c75a24453a6b",
   "metadata": {},
   "source": [
    "Step 1. Katib hyperparameter tuning task\n",
    "Create the Kubeflow Pipelines task for the Katib hyperparameter tuning. This Experiment uses \"random\" algorithm and TFJob for the Trial's worker.\n",
    "\n",
    "The Katib Experiment is similar to this example: https://github.com/kubeflow/katib/blob/master/examples/v1beta1/tfjob-example.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578588e-aa3f-44e5-9d0c-acf4b006024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "version=datetime.now().isoformat(timespec=\"seconds\").replace(':','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9498f9-7a19-4eb8-bec4-9b3ea6b776ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the Experiment name, namespace and number of training steps in the arguments.\n",
    "def create_katib_experiment_task(experiment_name, experiment_namespace, training_steps):\n",
    "    # Trial count specification.\n",
    "    max_trial_count = 10\n",
    "    max_failed_trial_count = 3\n",
    "    parallel_trial_count = 10\n",
    "\n",
    "    # Objective specification.\n",
    "    objective = V1beta1ObjectiveSpec(\n",
    "        type=\"minimize\",\n",
    "        goal=0.001,\n",
    "        objective_metric_name=\"loss\"\n",
    "    )\n",
    "\n",
    "    # Algorithm specification.\n",
    "    algorithm = V1beta1AlgorithmSpec(\n",
    "        algorithm_name=\"random\",\n",
    "    )\n",
    "\n",
    "    # Experiment search space.\n",
    "    # In this example we tune learning rate and batch size.\n",
    "    parameters = [\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"learning_rate\",\n",
    "            parameter_type=\"double\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"0.02\",\n",
    "                max=\"0.2\"\n",
    "            ),\n",
    "        ),\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"batch_size\",\n",
    "            parameter_type=\"int\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"25\",\n",
    "                max=\"70\"\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Experiment Trial template.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    trial_spec = {\n",
    "        \"apiVersion\": \"kubeflow.org/v1\",\n",
    "        \"kind\": \"TFJob\",\n",
    "        \"spec\": {\n",
    "            \"tfReplicaSpecs\": {\n",
    "                \"Chief\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"Worker\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Configure parameters for the Trial template.\n",
    "    trial_template = V1beta1TrialTemplate(\n",
    "        primary_container_name=\"tensorflow\",\n",
    "        trial_parameters=[\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"learningRate\",\n",
    "                description=\"Learning rate for the training model\",\n",
    "                reference=\"learning_rate\"\n",
    "            ),\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"batchSize\",\n",
    "                description=\"Batch size for the model\",\n",
    "                reference=\"batch_size\"\n",
    "            ),\n",
    "        ],\n",
    "        trial_spec=trial_spec\n",
    "    )\n",
    "\n",
    "    # Create an Experiment from the above parameters.\n",
    "    experiment_spec = V1beta1ExperimentSpec(\n",
    "        max_trial_count=max_trial_count,\n",
    "        max_failed_trial_count=max_failed_trial_count,\n",
    "        parallel_trial_count=parallel_trial_count,\n",
    "        objective=objective,\n",
    "        algorithm=algorithm,\n",
    "        parameters=parameters,\n",
    "        trial_template=trial_template\n",
    "    )\n",
    "\n",
    "    # Create the KFP task for the Katib Experiment.\n",
    "    # Experiment Spec should be serialized to a valid Kubernetes object.\n",
    "    katib_experiment_launcher_op = components.load_component_from_url(\n",
    "        \"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml\")\n",
    "    op = katib_experiment_launcher_op(\n",
    "        experiment_name=f'{experiment_name}-{version}z'.lower(),\n",
    "        experiment_namespace=experiment_namespace,\n",
    "        experiment_spec=ApiClient().sanitize_for_serialization(experiment_spec),\n",
    "        experiment_timeout_minutes=60,\n",
    "        delete_finished_experiment=False)\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82cc91-7e33-4ca6-bdaa-52125f43caf4",
   "metadata": {},
   "source": [
    "Step 2. TFJob training task\n",
    "Create the Kubeflow Pipelines task for the TFJob training. In this example TFJob runs the Chief and Worker with 1 replica.\n",
    "\n",
    "Learn more about TFJob replica specifications in the Kubeflow docs: https://www.kubeflow.org/docs/components/training/tftraining/#what-is-tfjob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232a243-bceb-4645-9273-bd6f82230ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts Katib Experiment HP results to args.\n",
    "def convert_katib_results(katib_results) -> str:\n",
    "    import json\n",
    "    import pprint\n",
    "    katib_results_json = json.loads(katib_results)\n",
    "    print(\"Katib results:\")\n",
    "    pprint.pprint(katib_results_json)\n",
    "    best_hps = []\n",
    "    for pa in katib_results_json[\"currentOptimalTrial\"][\"parameterAssignments\"]:\n",
    "        if pa[\"name\"] == \"learning_rate\":\n",
    "            best_hps.append(\"--tf-learning-rate=\" + pa[\"value\"])\n",
    "        elif pa[\"name\"] == \"batch_size\":\n",
    "            best_hps.append(\"--tf-batch-size=\" + pa[\"value\"])\n",
    "    print(\"Best Hyperparameters: {}\".format(best_hps))\n",
    "    return \" \".join(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c7947-3ba9-44cd-828f-bf30f14375ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the TFJob name, namespace, number of training steps, output of Katib and model volume tasks in the arguments.\n",
    "def create_tfjob_task(tfjob_name, tfjob_namespace, training_steps, katib_op, model_volume_op):\n",
    "    import json\n",
    "    # Get parameters from the Katib Experiment.\n",
    "    # Parameters are in the format \"--tf-learning-rate=0.01 --tf-batch-size=100\"\n",
    "    convert_katib_results_op = components.func_to_container_op(convert_katib_results)\n",
    "    best_hp_op = convert_katib_results_op(katib_op.output)\n",
    "    best_hps = str(best_hp_op.output)\n",
    "\n",
    "    # Create the TFJob Chief and Worker specification with the best Hyperparameters.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    tfjob_chief_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\"\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                            \"python /opt/model.py --tf-export-dir=/mnt/export --tf-model-dir=/mnt/export/model --tf-train-steps={} {}\".format(training_steps, best_hps)\n",
    "                        ],\n",
    "                        \"volumeMounts\": [\n",
    "                            {\n",
    "                                \"mountPath\": \"/mnt/export\",\n",
    "                                \"name\": \"model-volume\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"name\": \"model-volume\",\n",
    "                        \"persistentVolumeClaim\": {\n",
    "                            \"claimName\": str(model_volume_op.outputs[\"name\"])\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tfjob_worker_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\",\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                          \"python /opt/model.py --tf-export-dir=/mnt/export --tf-model-dir=/mnt/export/model --tf-train-steps={} {}\".format(training_steps, best_hps) \n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the KFP task for the TFJob.\n",
    "    tfjob_launcher_op = components.load_component_from_url(\n",
    "        \"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/launcher/component.yaml\")\n",
    "    # override the image that is very old and does not allow deleting the job when done\n",
    "    tfjob_launcher_op.component_spec.implementation.container.image = 'sjc.ocir.io/bigdatadatasciencelarge/ml-pipeline-kubeflow-tfjob:latest'\n",
    "    \n",
    "    op = tfjob_launcher_op(\n",
    "        name=tfjob_name,\n",
    "        namespace=tfjob_namespace,\n",
    "        chief_spec=json.dumps(tfjob_chief_spec),\n",
    "        worker_spec=json.dumps(tfjob_worker_spec),\n",
    "        ttl_seconds_after_finished=120,\n",
    "        tfjob_timeout_minutes=60,\n",
    "        # delete finished jobs so we can run it again / update\n",
    "        delete_finished_tfjob=True\n",
    "    )\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6aada-acf1-4b70-bd8a-a91cc233fd11",
   "metadata": {},
   "source": [
    "Step 3. KFServing inference\n",
    "Create the Kubeflow Pipelines task for the KFServing inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd3dac-fb41-43e3-843b-b60ad863ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the model name, namespace, output of the TFJob and model volume tasks in the arguments.\n",
    "def create_kfserve_task(model_name, model_namespace, tfjob_op, model_volume_op):\n",
    "\n",
    "    inference_service = '''\n",
    "apiVersion: \"serving.kserve.io/v1beta1\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: {}\n",
    "  namespace: {}\n",
    "  annotations:\n",
    "    \"sidecar.istio.io/inject\": \"false\"\n",
    "spec:\n",
    "  predictor:\n",
    "    model:\n",
    "      modelFormat:\n",
    "        name: tensorflow\n",
    "      storageUri: \"pvc://{}/\"\n",
    "'''.format(model_name, model_namespace, str(model_volume_op.outputs[\"name\"]))\n",
    "\n",
    "    kfserve_launcher_op = components.load_component_from_url(\n",
    "        'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kserve/component.yaml')\n",
    "    \n",
    "    # use 'apply' action which is equivalent to 'create' if not exist or 'update' if exists.\n",
    "    kfserve_launcher_op(action=\"apply\", \n",
    "                        inferenceservice_yaml=inference_service,\n",
    "                        watch_timeout='1200'\n",
    "                       ).after(tfjob_op).set_caching_options(enable_caching=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01e0ea-6f87-4c1e-a3e6-0c160801bad8",
   "metadata": {},
   "source": [
    "Run the Kubeflow Pipeline\n",
    "You should create the Kubeflow Pipeline from the above tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68eb96-1633-4836-a4ed-387c6746e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"mnist-e2e\"\n",
    "namespace=environ.get('NB_PREFIX').split('/')[2]\n",
    "training_steps=\"300\"\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End to End Pipeline\",\n",
    "    description=\"An end to end mnist example including hyperparameter tuning, train and inference\"\n",
    ")\n",
    "def mnist_pipeline(name=name, namespace=namespace, training_steps=training_steps):\n",
    "    # Run the hyperparameter tuning with Katib.\n",
    "    katib_op = create_katib_experiment_task(name, namespace, training_steps)\n",
    "\n",
    "    # Create volume to train and serve the model.\n",
    "    model_volume_op = dsl.VolumeOp(\n",
    "        name=\"model-volume\",\n",
    "        resource_name=\"model-volume\",\n",
    "        size=\"1Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "\n",
    "    # Run the distributive training with TFJob.\n",
    "    tfjob_op = create_tfjob_task(f'{name}-{version}z'.lower(), namespace, training_steps, katib_op, model_volume_op)\n",
    "\n",
    "    # Create the KFServe inference.\n",
    "    create_kfserve_task(name, namespace, tfjob_op, model_volume_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3151-946a-4fb4-a59d-5386e4b431e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(create_katib_experiment_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281862c-2e05-4a61-afd9-3ecdb9fbbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Kubeflow Pipeline in the user's namespace.\n",
    "kfp_client=kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4578a3-9002-4352-bb2d-0394836be8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_name = f'{name}-{version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbdbbd-81a6-430f-a5d0-41ac5ad9021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(mnist_pipeline, f'{upload_name}.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472e3c3-f109-45ec-8a19-ee73357aea75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    kfp_client.upload_pipeline(f'{upload_name}.yaml', description='MNIST-e2e')\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b750968-e6e3-4db2-a657-fbd2357c548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = kfp_client.create_run_from_pipeline_func(mnist_pipeline, namespace=namespace, arguments={}).run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447303ae-c9f4-4996-bdd8-8717fdd26c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for run to succeed\n",
    "kfp_run = kfp_client.get_run(run_id=run_id)\n",
    "while kfp_run.run.status != \"Succeeded\":\n",
    "    kfp_run = kfp_client.get_run(run_id=run_id)\n",
    "    print('.',end='')\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1630d-fe1a-4483-9136-ddef8519c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Pipeline Run should be succeeded.\n",
    "kfp_run = kfp_client.get_run(run_id=run_id)\n",
    "\n",
    "# Specify the image URL here.\n",
    "image_url = \"https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/kubeflow-pipelines/images/9.bmp\"\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "data = np.array(image.convert('L').resize((28, 28))).astype('float').reshape(-1, 28, 28, 1)\n",
    "data_formatted = np.array2string(data, separator=\",\", formatter={\"float\": lambda x: \"%.1f\" % x})\n",
    "json_request = '{{ \"instances\" : {} }}'.format(data_formatted)\n",
    "with open('mnist-e2e-9.json', 'w') as f:\n",
    "    f.write(json_request)\n",
    "\n",
    "# Specify the internal prediction URL, protocol is v1 in this case.\n",
    "url = \"http://{}-predictor-default.{}.svc.cluster.local/v1/models/{}:predict\".format(name, namespace, name)\n",
    "response = requests.post(url, data=json_request)\n",
    "\n",
    "print(\"Prediction for the image\")\n",
    "display(image)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33d8a7-8361-45b6-9cc7-ddd937c56863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
